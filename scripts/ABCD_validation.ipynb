{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT as rt\n",
    "import csv\n",
    "import re\n",
    "import sys\n",
    "import collections\n",
    "\n",
    "from collections import OrderedDict\n",
    "import uproot\n",
    "\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd().replace('scripts', 'lib'))\n",
    "\n",
    "import tdrstyle\n",
    "style = tdrstyle.setTDRStyle()\n",
    "\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ntuples\n",
    "Load the data ntuples to validate the ABCD method in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/eos/uscms/store/user/cmsdas/2024/long_exercises/MDS/data/'\n",
    "data_file = path + 'Run2_displacedJetMuonNtupler_V1p17_Data2016_Data2017_Data2018-HighMET_goodLumi.root'\n",
    "root_dir = uproot.open(data_file) \n",
    "tree = root_dir['MuonSystem']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOT Control Region Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply all the vetoes in the previous episode and require cluster time < -12.5 ns to select for the OOT validation region. <br>\n",
    "You will replace the `REPLACE_ME` variable by -12.5 to apply the OOT selection\n",
    "A few other selections on the cluster number of station and average station are also applied to be aligned with the analysis, which we have introduced in the `Reconstruction` episode\n",
    "\n",
    "The branch $N_\\text{hits}$ and $\\Delta\\phi\\text{(cluster, MET)}$ are saved as numpy arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = tree\n",
    "        \n",
    "########### SELECTION: CLUSTERS ############\n",
    "\n",
    "\n",
    "sel_rechitcluster = np.abs(T['cscRechitClusterEta'].array()) < 2.0\n",
    "\n",
    "me1112_veto = 0\n",
    "sel_rechitcluster = np.logical_and(sel_rechitcluster, T['cscRechitClusterNRechitChamberPlus11'].array() <= me1112_veto)\n",
    "sel_rechitcluster = np.logical_and(sel_rechitcluster, T['cscRechitClusterNRechitChamberPlus12'].array() <= me1112_veto)\n",
    "sel_rechitcluster = np.logical_and(sel_rechitcluster, T['cscRechitClusterNRechitChamberMinus11'].array() <= me1112_veto)\n",
    "sel_rechitcluster = np.logical_and(sel_rechitcluster, T['cscRechitClusterNRechitChamberMinus12'].array() <= me1112_veto)\n",
    "\n",
    "sel_rechitcluster = np.logical_and(sel_rechitcluster, T['cscRechitCluster_match_MB1Seg_0p4'].array() <= me1112_veto)\n",
    "sel_rechitcluster = np.logical_and(sel_rechitcluster, T['cscRechitCluster_match_RE12_0p4'].array() <= me1112_veto)\n",
    "sel_rechitcluster = np.logical_and(sel_rechitcluster, T['cscRechitCluster_match_RB1_0p4'].array() <= me1112_veto)\n",
    "\n",
    "sel_rechitcluster = np.logical_and( sel_rechitcluster, T['cscRechitClusterJetVetoPt'].array() < 10)\n",
    "sel_rechitcluster = np.logical_and( sel_rechitcluster, T['cscRechitClusterMuonVetoPt'].array() < 20)\n",
    "sel_rechitcluster = np.logical_and(sel_rechitcluster, T['cscRechitClusterTimeSpread'].array() <= 20)\n",
    "\n",
    "# OOT selection\n",
    "sel_rechitcluster = np.logical_and(sel_rechitcluster,  T['cscRechitClusterTime'].array() < REPLACE_ME)\n",
    "\n",
    "\n",
    "\n",
    "########### SELECTION: JETS ############\n",
    "\n",
    "sel_jet = np.logical_and(T['jetPt'].array() > 30, np.abs(T['jetEta'].array()) < 2.4 )\n",
    "sel_jet = np.logical_and(sel_jet, T['jetTightPassId'].array())\n",
    "\n",
    "########### SELECTION: EVENTS ############\n",
    "\n",
    "sel_ev = T['METTrigger'].array()\n",
    "sel_ev  = np.logical_and(sel_ev,np.sum(sel_rechitcluster,axis=1) >= 1)\n",
    "sel_ev = np.logical_and(sel_ev ,T['met'].array() > 200)\n",
    "sel_ev = np.logical_and(sel_ev , np.sum(sel_jet,axis=1)>=1)\n",
    "sel_ev = np.logical_and(sel_ev,T['metFilters'].array())\n",
    "\n",
    "\n",
    "##### cut based ID ####\n",
    "cscRechitClusterNStation = T['cscRechitClusterNStation'].array()[sel_rechitcluster][sel_ev][:,0]\n",
    "cscRechitClusterEta = T['cscRechitClusterEta'].array()[sel_rechitcluster][sel_ev][:,0]\n",
    "cscRechitClusterPhi = T['cscRechitClusterPhi'].array()[sel_rechitcluster][sel_ev][:,0]\n",
    "cscRechitClusterAvgStation = T['cscRechitClusterAvgStation'].array()[sel_rechitcluster][sel_ev][:,0]\n",
    "cond2 = np.logical_and(np.abs(cscRechitClusterAvgStation)==2, np.abs(cscRechitClusterEta) < 1.6)\n",
    "cond3 = np.logical_and(np.abs(cscRechitClusterAvgStation)==3, np.abs(cscRechitClusterEta) < 1.6)\n",
    "cond4 = np.logical_and(np.abs(cscRechitClusterAvgStation)==4, np.abs(cscRechitClusterEta) < 1.8)\n",
    "cond1 = np.logical_and(cscRechitClusterNStation==1, np.logical_or(np.logical_or(np.abs(cscRechitClusterAvgStation)==1, cond2), np.logical_or(cond3, cond4)))\n",
    "cond2 = np.logical_and(cscRechitClusterNStation > 1, np.abs(cscRechitClusterEta) < 1.9)\n",
    "bdt_sel = np.logical_or(np.logical_or(cond1, cond2), np.logical_or(cond3, cond4))\n",
    "\n",
    "#### Save variables needed for ABCD ####                                   \n",
    "                                   \n",
    "deltaPhi = T['cscRechitClusterMet_dPhi'].array()[sel_rechitcluster][sel_ev][:,0][bdt_sel]\n",
    "Nhits = T['cscRechitClusterSize'].array()[sel_rechitcluster][sel_ev][:,0][bdt_sel]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot distribution of dphi and Nrechits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the 2D distributions of the two variables to see if there's any obvious correlations\n",
    "Replace the `REPLACE_ME` variable to fill in the `TH2D` histogram with `Nhits` and `deltaPhi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = rt.TCanvas('c','c', 1000, 800)\n",
    "\n",
    "h = rt.TH2D('', '', 25,50,300,25,0,3.2)\n",
    "h.SetXTitle('N_{hits}')\n",
    "h.SetYTitle('#Delta#phi (cluster,met)')\n",
    "h.SetZTitle('Events')\n",
    "for i in range(len(Nhits)):\n",
    "    h.Fill(REPLACE_ME)\n",
    "\n",
    "h.Draw('colz')\n",
    "c.SetRightMargin(0.2)\n",
    "c.Draw()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABCD validation (Scan $N_\\text{hits}$ or $\\Delta\\phi\\mathrm{(cluster, MET)}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you will calculate the number of observed events in bin A, B, C, and D and calculate the expected background in bin A using $A = B\\times D/C$ and check if the expected background from the ABCD relation agree with the observed number of events in bin A <br>\n",
    "<br>\n",
    "The number of observed events in bin A is already filled in, please complete the number of events for bin B, C, and D, where `FILL IN HERE` is indicated. <br>\n",
    "Additionally, calculate the prediction of bin A from the ABCD relationship, and the statistical uncertainty of the prediction propogated from bin B, C, and D, by filling in `pred` and `unc_pred`\n",
    "\n",
    "The `scan_nhits` flag determines whether we scan the threshold of $N_\\text{hits}$ or $\\Delta\\phi\\mathrm{(cluster, MET)}$. When `scan_nhits = 1`, we scan $N_\\text{hits}$, when `scan_nhits = 0`, we scan  $\\Delta\\phi\\mathrm{(cluster, MET)}$. <br>\n",
    "<br>\n",
    "Does the prediction agree with the observation for all thresholds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ev = 5000\n",
    "\n",
    "scan_nhits = 1\n",
    "\n",
    "if scan_nhits:\n",
    "    dphi_scan = [0.75]\n",
    "    nhits_scan = np.arange(60,200,10)\n",
    "else:\n",
    "    dphi_scan = np.arange(9,22,1)/20\n",
    "    nhits_scan = [130]\n",
    "\n",
    "    \n",
    "print('cut \\t A \\t B \\t C \\t D \\t prediction \\t uncertainty')\n",
    "print()\n",
    "for N_RECHIT_CUT in nhits_scan:\n",
    "    for DPHI_CUT in dphi_scan:\n",
    "        var = np.abs(deltaPhi)\n",
    "        a = np.sum(np.logical_and(Nhits>=N_RECHIT_CUT, np.abs(deltaPhi)<DPHI_CUT))\n",
    "        b = # FILL IN HERE\n",
    "        c = # FILL IN HERE\n",
    "        d = # FILL IN HERE\n",
    "\n",
    "        pred = # FILL IN HERE\n",
    "        unc_pred = # FILL IN HERE\n",
    "        \n",
    "        if scan_nhits: print(N_RECHIT_CUT, '\\t',a,'\\t',b,'\\t',c,'\\t',d,'\\t', round(pred, 2), '\\t',round( unc_pred, 2))\n",
    "        else: print(DPHI_CUT, '\\t',a,'\\t',b,'\\t',c,'\\t',d,'\\t', round(pred, 2), '\\t', round( unc_pred, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
