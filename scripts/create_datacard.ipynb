{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.28/00\n",
      "3.9.12 (main, Jun  7 2022, 16:09:12) \n",
      "[GCC 11.2.0]\n"
     ]
    }
   ],
   "source": [
    "import ROOT as rt\n",
    "import uproot\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import csv\n",
    "import os\n",
    "import math\n",
    "import sys\n",
    "sys.path.append(os.getcwd().replace('scripts', 'lib'))\n",
    "\n",
    "import importlib\n",
    "import helper\n",
    "importlib.reload(sys.modules['helper'])\n",
    "from helper import  weight_calc, make_datacard\n",
    "\n",
    "import tdrstyle\n",
    "a = tdrstyle.setTDRStyle()\n",
    "\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ntuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "MC_40_100\n",
      "MC_40_1000\n",
      "MC_40_10000\n",
      "MC_40_100000\n"
     ]
    }
   ],
   "source": [
    "fpath =OrderedDict()\n",
    "tree = OrderedDict()\n",
    "\n",
    "prod =['ggH']\n",
    "decay = 'bbbb'\n",
    "\n",
    "\n",
    "\n",
    "mass = [40]\n",
    "OLD_CTAU = np.array([100, 1000, 10000, 100000])#in mm\n",
    "\n",
    "\n",
    "\n",
    "path = '/eos/uscms/store/user/cmsdas/2024/long_exercises/MDS/data/'\n",
    "fpath['data'] = path + 'Run2_displacedJetMuonNtupler_V1p17_Data2016_Data2017_Data2018-HighMET_goodLumi.root'\n",
    "\n",
    "\n",
    "path = '/eos/uscms/store/user/cmsdas/2024/long_exercises/MDS/signal/nocuts/'\n",
    "for m in mass:\n",
    "    for ct in OLD_CTAU:\n",
    "        key = 'MC_'+str(m)+'_'+str(ct)                       \n",
    "        fpath[key] = path +  'ggH_HToSSTobbbb_MH-125_MS-40_ctau-'+str(ct)+'_137000pb_weighted.root'\n",
    "\n",
    "NEvents = {}\n",
    "NEvents_genweight = {}\n",
    "for k,v in fpath.items():\n",
    "    root_dir = uproot.open(v) \n",
    "    if not root_dir: \n",
    "        print(k, \"zombie\")\n",
    "        continue\n",
    "    tree[k] = root_dir['MuonSystem']\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "MC_40_100\n",
      "MC_40_1000\n",
      "MC_40_10000\n",
      "MC_40_100000\n"
     ]
    }
   ],
   "source": [
    "deltaPhi = {}\n",
    "Nhits = {}\n",
    "weight = {}\n",
    "gLLP_ctau = {}\n",
    "\n",
    "\n",
    "for k, T in tree.items():\n",
    "    \n",
    "    ########### SELECTION: CLUSTERS ############\n",
    "\n",
    "    sel_rechitcluster = np.abs(T['cscRechitClusterEta'].array()) < 2.0\n",
    "\n",
    "    me1112_veto = 0\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T['cscRechitClusterNRechitChamberPlus11'].array() <= me1112_veto)\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T['cscRechitClusterNRechitChamberPlus12'].array() <= me1112_veto)\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T['cscRechitClusterNRechitChamberMinus11'].array() <= me1112_veto)\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T['cscRechitClusterNRechitChamberMinus12'].array() <= me1112_veto)\n",
    "\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T['cscRechitCluster_match_MB1Seg_0p4'].array() <= me1112_veto)\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T['cscRechitCluster_match_RE12_0p4'].array() <= me1112_veto)\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T['cscRechitCluster_match_RB1_0p4'].array() <= me1112_veto)\n",
    "\n",
    "    sel_rechitcluster = np.logical_and( sel_rechitcluster, T['cscRechitClusterJetVetoPt'].array() < 10)\n",
    "    sel_rechitcluster = np.logical_and( sel_rechitcluster, T['cscRechitClusterMuonVetoPt'].array() < 20)\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T['cscRechitClusterTimeSpread'].array() < 20)\n",
    "\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, np.logical_and(T['cscRechitClusterTime'].array() < 12.5, \\\n",
    "                                                                         T['cscRechitClusterTime'].array() > -5.0))\n",
    "\n",
    "    ########### SELECTION: JETS ############\n",
    "\n",
    "    sel_jet = np.logical_and(T['jetPt'].array() > 30, np.abs(T['jetEta'].array()) < 2.4 )\n",
    "    sel_jet = np.logical_and(sel_jet, T['jetTightPassId'].array())\n",
    "\n",
    "    ########### SELECTION: EVENTS ############\n",
    "    sel_ev = T['METTrigger'].array()\n",
    "    sel_ev = np.logical_and(sel_ev ,T['met'].array() > 200)\n",
    "    sel_ev = np.logical_and(sel_ev,T['metFilters'].array())\n",
    "    sel_ev = np.logical_and(sel_ev , np.sum(sel_jet,axis=1)>=1)\n",
    "    sel_ev  = np.logical_and(sel_ev,np.sum(sel_rechitcluster,axis=1) >= 1)\n",
    "\n",
    "\n",
    "    ##### cut based ID ####\n",
    "    cscRechitClusterNStation = T['cscRechitClusterNStation'].array()[sel_rechitcluster][sel_ev][:,0]\n",
    "    cscRechitClusterEta = T['cscRechitClusterEta'].array()[sel_rechitcluster][sel_ev][:,0]\n",
    "    cscRechitClusterAvgStation = T['cscRechitClusterAvgStation'].array()[sel_rechitcluster][sel_ev][:,0]\n",
    "    cond2 = np.logical_and(np.abs(cscRechitClusterAvgStation)==2, np.abs(cscRechitClusterEta) < 1.6)\n",
    "    cond3 = np.logical_and(np.abs(cscRechitClusterAvgStation)==3, np.abs(cscRechitClusterEta) < 1.6)\n",
    "    cond4 = np.logical_and(np.abs(cscRechitClusterAvgStation)==4, np.abs(cscRechitClusterEta) < 1.8)\n",
    "    cond1 = np.logical_and(cscRechitClusterNStation==1, np.logical_or(np.logical_or(np.abs(cscRechitClusterAvgStation)==1, cond2), np.logical_or(cond3, cond4)))\n",
    "    cond2 = np.logical_and(cscRechitClusterNStation > 1, np.abs(cscRechitClusterEta) < 1.9)\n",
    "    bdt_sel = np.logical_or(np.logical_or(cond1, cond2), np.logical_or(cond3, cond4))\n",
    "\n",
    "    #### Save variables needed for ABCD ####                                   \n",
    "\n",
    "    deltaPhi[k] = T['cscRechitClusterMet_dPhi'].array()[sel_rechitcluster][sel_ev][:,0][bdt_sel]\n",
    "    Nhits[k] = T['cscRechitClusterSize'].array()[sel_rechitcluster][sel_ev][:,0][bdt_sel]\n",
    "    weight[k] = (T['weight'].array()*T['pileupWeight'].array()*T['metSF'].array())[sel_ev][bdt_sel]\n",
    "    gLLP_ctau[k] = T['gLLP_ctau'].array()[sel_ev][bdt_sel]\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# signal uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggH_higgsPt = {}\n",
    "ggH_qcdScale = {}\n",
    "ggH_pdf = {}\n",
    "\n",
    "\n",
    "for m in mass:\n",
    "    for ct in OLD_CTAU:\n",
    "            key = 'MC_'+str(m)+'_'+str(ct)         \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            ggH_higgsPt[key] = [0.208, 0.205, 0.205,0.207,0.134, 0.133,0.133,0.134] #down*4/up*4\n",
    "            ggH_qcdScale[key] = [0.067]*4+[0.046]*4 #down/up\n",
    "            ggH_pdf[key] = [0.032]*4\n",
    "\n",
    "\n",
    "\n",
    "sig_unc_temp = [ggH_higgsPt, ggH_qcdScale, ggH_pdf]\n",
    "sig_unc_name = ['ggH_higgsPt', 'ggH_qcdScale', 'ggH_pdf']\n",
    "\n",
    "\n",
    "assert(len(sig_unc_temp)==len(sig_unc_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/uscms/home/christiw/nobackup/CMSSW_11_3_4/src/MDS_CMSDAS2023/combine/datacards/\n"
     ]
    }
   ],
   "source": [
    "outDataCardsDir = '/uscms/home/christiw/nobackup/CMSSW_11_3_4/src/MDS_CMSDAS2023/combine/datacards/'\n",
    "if not os.path.isdir(outDataCardsDir):os.makedirs(outDataCardsDir)\n",
    "print(outDataCardsDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make datacard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3   3 121  50]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import importlib\n",
    "import helper\n",
    "importlib.reload(sys.modules['helper'])\n",
    "from helper import  weight_calc, make_datacard\n",
    "\n",
    "N_RECHIT_CUT = 130\n",
    "DPHI_CUT = 0.75\n",
    "\n",
    "ctaus = ['5','10','15','20','30','40', '50','60', '100', '125','150','200','300','500','600','700','800','900','1000', '2000','3000','4000', '5000', '6000','7000','8000','10000', '20000','30000','50000',\\\n",
    "         '100000', '200000', '300000', '500000', '1000000', '2000000', '3000000', '5000000', '6000000', '10000000'] #mm\n",
    "\n",
    "bkg_unc = [] #ABCD closure, sum of stats from two VR\n",
    "bkg_unc_name = []\n",
    "\n",
    "\n",
    "bkg = []\n",
    "bkg_unc = []\n",
    "\n",
    "k = 'data'\n",
    "a = np.count_nonzero(np.logical_and(Nhits[k] >= N_RECHIT_CUT, np.abs(deltaPhi[k]) < DPHI_CUT)) \n",
    "b = np.count_nonzero(np.logical_and(Nhits[k] >= N_RECHIT_CUT, np.abs(deltaPhi[k]) >= DPHI_CUT))\n",
    "c = np.count_nonzero(np.logical_and(Nhits[k] < N_RECHIT_CUT, np.abs(deltaPhi[k]) >= DPHI_CUT)) \n",
    "d = np.count_nonzero(np.logical_and(Nhits[k] < N_RECHIT_CUT, np.abs(deltaPhi[k]) < DPHI_CUT)) \n",
    "observation= np.array([a,b,c,d])\n",
    "print(observation)\n",
    "\n",
    "#####\n",
    "# start adding signal\n",
    "#####\n",
    "\n",
    "sig_norm = []\n",
    "for m in mass:\n",
    "    for ct in ctaus:\n",
    "        modelName = 'ggH_HToSSTo'+decay+ '_mh125_mx'+str(m)+'_ctau'+str(ct)+'mm'\n",
    "\n",
    "        \n",
    "        signal_rate = []\n",
    "        mc_stat_unc = []\n",
    "        gmn = []\n",
    "        sig_unc = []\n",
    "\n",
    "        ctf = int(ct)\n",
    "        ct0 = 10**math.ceil(math.log10(ctf))\n",
    "        ct0 = max(ct0, OLD_CTAU[0])\n",
    "        ct0 = min(ct0, OLD_CTAU[-1])\n",
    "        k = 'MC_'+str(m)+'_'+str(ct0)\n",
    "        weight_ctau = weight_calc(gLLP_ctau[k], int(ct)/10, int(ct0)/10) # convert everything to cm\n",
    "\n",
    "        w = weight[k]*weight_ctau\n",
    "        cond = np.logical_and(Nhits[k]>=N_RECHIT_CUT, deltaPhi[k]<DPHI_CUT)\n",
    "        signal_rate.append(np.sum(w[cond]))\n",
    "        \n",
    "        cond = np.logical_and(Nhits[k]>=N_RECHIT_CUT, deltaPhi[k]>=DPHI_CUT)\n",
    "        signal_rate.append(np.sum(w[cond]))\n",
    "        \n",
    "        cond = np.logical_and(Nhits[k]<N_RECHIT_CUT, deltaPhi[k]>=DPHI_CUT)\n",
    "        signal_rate.append(np.sum(w[cond]))\n",
    "        \n",
    "        cond = np.logical_and(Nhits[k]<N_RECHIT_CUT, deltaPhi[k]<DPHI_CUT)\n",
    "        signal_rate.append(np.sum(w[cond]))\n",
    "              \n",
    "        for j, ele in enumerate(sig_unc_temp):sig_unc.append(ele[k])\n",
    "            \n",
    "        make_datacard(outDataCardsDir, modelName, signal_rate, observation, sig_unc, sig_unc_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
